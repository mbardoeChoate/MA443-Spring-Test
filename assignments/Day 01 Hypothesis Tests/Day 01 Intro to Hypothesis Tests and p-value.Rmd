---
title: "Intro to Hypothesis Tests"
author: "Matthew Bardoe & Carey Kopeikin"
date: "2/21/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=TRUE)
```

## Hypothesis Tests

Imagine that you are a politician and you are deciding whether to support the policy for full body scans 
https://www.openintro.org/data/index.php?data=full_body_scan. You decide to support the policy as long as less than 17% of the population is against it. When looking at the data in ```full_body_scan.csv``` you see that the sample proportion of those who say government should not use it is 0.1495163 but that is only the proportion in the sample. It is just an estimate of the true proportion. Your chance of winning reelection is slim so you need to make sure that you make the correct choice. One of the main ways statisticians answer these question is to imagine that the true mean is 17 and then try to figure out how strange the value you got would be. We have done something very similar to this when looking at the Normal model.

```{r}
# load the data

scan <- read.csv("full_body_scan.csv")
```

```{r}
# define variables

# number of successes
x <- sum(scan$answer == "should not")

# sample size
n <- length(scan$answer)

# sample proportion of successes
phat <- x/n 

# sample proportion of failures
qhat <- 1-phat

# assumed true proportion of successes
p = .17

#assumed true proportion of failures
q = 1-p
```


If we have a sample in which: 
* each observation was collected independently
* the variable is categorical
* the variable has only two options (or is made to have 2 options)
* the sample is large enough
then we can use the Normal model to answer questions like the one above.

The graph below represents the sampling distribution of phats. That is if we took infinite samples of 1137 people (our n) from a population with a true proportion of .17 this is the relative likelyhood (called the density) of those samples. Its center is at .17 which is our assumed true p and the standard deviation is found using the formula
$$ SD(phat) = \sqrt{ \frac{p * q}{n}}$$

```{r}
SDphat <- sqrt( (p*q)/n )
SDphat
```

So this Normal Model can be written as N(.17, 0.01113995 ) or as N( p, SD(phat) )

```{r}
curve( dnorm( x, p, SDphat)/n,
       xlim=c(p-4*SDphat, p+4*SDphat),
       lwd = 3, 
       main="Sampling Distribution of The \n Sampling Proportion of Should Nots",
       xlab="Proportion of Should Nots",
       ylab="Density",
       col = "purple",
       )
```



The phat we got in our sample was .1495 which I will now add to the graph:

```{r}

curve( dnorm( x, p, SDphat)/n,
       xlim=c(p-4*SDphat, p+4*SDphat),
       lwd = 3, 
       main="Sampling Distribution of The \n Sampling Proportion of Should Nots",
       xlab="Proportion of Should Nots",
       ylab="Density",
       col = "purple",
       )

segments(phat, 0, phat, dnorm( phat, p, SDphat)/n,
         col="red",
         lwd=5)

polygon(x=c(0, 
            seq(from=-1, to=phat, by=.0001),
            phat),
        y=c(0,
            dnorm(seq(from=-1, to=phat, by=.0001),mean=p, sd=SDphat)/n,
            0),
        col="yellow")

```

The yellow shading is the percentage of the graph that is lower/more extreme than the value we got. In other words it is the probability of getting results at least as extreme as observed given that the null hypothesis is true.

**What is another name for the yellow area?**


In order to find the yellow area we need to know how many standard deviations away from the mean our observed value is.

Now we can find out how many standard deviations from the mean we are using the following formula

$$ \frac{ \hat{p} - p }{ SD(\hat{p}) } \\ or \\ \frac{ \hat{p} - p }{ \sqrt{\frac{ pq }{n}} } $$
```{r}
(phat - p) / SDphat
```

*What value did we just find?*





Now we ask what is the probability that a value is less than -1.838763 sd from the mean? This is the p-value.
```{r}
pnorm( z )
```

Note that we can combine these steps using:
```{r}
pnorm( phat, p, sqrt(p*q/n) )
```

We can also use the function ```prop.test```:

```{r}
prop.test(x, n, p, conf.level = 0.95, alternative = "less", correct = FALSE)
```

In all of these cases we get a p-value of 0.03298


## P-Value

Remember that the actual definition is that a p-value: Is the probability of getting results at least as extreme as observed given that the null hypothesis is true.

*Question*
The seller of a loaded die claims that it will favor the outcome 6. We don’t believe that claim, and roll the die 200 times to test an appropriate hypothesis. Our p-value turns out to be 0.03. Which conclusion is appropriate? Explain.

a) There’s a 3% chance that the die is fair.
b) There’s a 97% chance that the die is fair.
c) There’s a 3% chance that a loaded die could randomly produce the results we observed, so it’s reasonable to conclude that the die is fair.
d) There’s a 3% chance that a fair die could randomly produce the results we observed, so it’s reasonable to
conclude that the die is loaded.


### Hypothesis

Whenever we talk about p-value there has be what is called a null hypothesis. Often the null hypothesis is the opposite of what we want to show. In the example above the null hypothesis was that the true proportion equaled .17. 

$$ H_0: p = .17$$

Note that the null hypothesis must always be the the true proportion *equals* a value and must always follow the form:

$$ H_0: p = p_0$$

The null hypothesis can never be that the true value is greater than, less than, or not equal to a value. The alternative hypothesis is that the true proportion is either: greater than, less than, or not equal to the value in the null hypothesis. 

In the example above our alternative hypothesis was:

$$ H_a: p < .17$$

The alternative hypothesis can never be equal to a value and must be of the form:

$$ H_a: p < p_0 \\ H_a: p > p_0 \\ H_a: p \neq p_0$$

Essentially we are setting up a straw man argument and then trying to knock it down. An argument of this type is sometimes called a reductio ad absurdum argument. Where we make a hypothesis and hope that the evidence contradicts that hypothesis by so much as to make the original hypothesis seen ridiculous. Then we can reject our initial hypothesis. What we hope to show is that given the observed data it would be ridiculous for us to believe the null hypothesis is true. 

## Rejecting the null hypothesis and alpha levels

In order to decide if we can reject the null hypothesis we have to decide how extreme is too extreme. In the past we have said that if the probability is less than 5% then it can be considered an outlier. There is no special reason to chose 5% but it is the most common cut off. The value that we choose to be the cut off value is called the alpha value of the test. Other common alpha values are .01 and .001. The alpha value should be chosen before gathering the data and is often dictated by an outside body for example a scientific journal or government agency. 

We have 2 options when evaluating p-value 

1. If the p-value is less than the alpha level we reject the null. We are essentially saying that, *the probability of getting results at least as extreme as observed (given that the null hypothesis is true)*, is so low that we do not believe that the null hypothesis could be true. Thus we would be forced to accept the alternative hypothesis. 

2. If the p-value is greater than the alpha level we *fail to reject the null*. *The probability of getting results at least as extreme as observed (given that the null hypothesis is true)* is not unreasonable and therefore we can not say the null hypothesis is unreasonable. Note that we can never accept the null hypothesis we can only fail to reject it. This is an extremely unsatisfying result. All this tells us is that we don't have enough evidence to say that the null hypothesis is wrong.





## Putting it all togeather

Here I will answer the question above the way I expect you to on a homework or test.

Imagine that you are a politician and you are deciding whether to support the policy for full body scans. Based on your polling numbers you decide to support the policy as long as less than 17% of the population is against it. When looking at the data in ```full_body_scan.csv``` you see that the sample proportion of those who say  government should not use it is 0.1495163 but by now you know that this is just an estimate of the true proportion. Your chance of winning reelection is slim so you need to make sure that you make the correct choice. Should you support the policy? Use a hypothesis test to make your choice using an alpha of .05 and then make a 95% confidence interval of the true proportion of people who are against full body scans.


*State the hypotheses:

$$ H_0: p = .17 \\ H_a: p < .17 $$


*Load data and collect summery statistics:
```{r}
# read in the data
scan <- read.csv("full_body_scan.csv")

# define variables
x <- sum(scan$answer == "should not")
n <- length(scan$answer)
phat <- x/n 
qhat <- 1-phat
p = .17
q = 1-p
```


* Make a graph:

```{r}

curve( dnorm( x, p, SDphat)/n,
       xlim=c(p-4*SDphat, p+4*SDphat),
       lwd = 3, 
       main="Sampling Distribution of The \n Sampling Proportion of Should Nots",
       xlab="Proportion of Should Nots",
       ylab="Density",
       col = "purple",
       )

segments(phat, 0, phat, dnorm( phat, p, SDphat)/n,
         col="red",
         lwd=5)

polygon(x=c(0, 
            seq(from=-1, to=phat, by=.0001),
            phat),
        y=c(0,
            dnorm(seq(from=-1, to=phat, by=.0001),mean=p, sd=SDphat)/n,
            0),
        col="yellow")

```

*Run the test:

```{r}
prop.test(x, n, p, alternative = "less", correct = FALSE)
```

*Evaluate the p-value:

The p-value of 0.03298 is less than my alpha of .05 thus I can reject the null hypothesis that the true percentage of Americans who believe that we should not use full body scans is 17% and accept the alternative hypothesis that the true percentage is less than 17%. 


*Make your conclusion:

My hypothesis test allowed me to conclude that the true percentage of Americans who believe that we should not use full body scans is less than 17%. Since I make my decisions solely on poll results will support the policy for full body scans. 



*Homework*

1. Write the null and alternative hypotheses you would use to test each of the following situations:

a)  In the 1950s only about 40% of high school graduates went on to college. Has the percentage changed?

b)  20% of cars of a certain model have needed costly transmission work after being driven between 50,000 and 100,000 miles. The manufacturer hopes that a redesign of a transmission component has solved this problem.

c)   We field-test a new-flavor soft drink, planning to market it only if we are sure that over 60% of the people like the flavor.



2. The National Center for Education Statistics monitors many aspects of elementary and secondary education nationwide. Their 1996 numbers are often used as a baseline to assess changes. In 1996 34% of students had not been absent from school even once during the previous month. In the 2000 survey, responses from 8302 students showed that this figure had slipped to 33%. Officials would, of course, be concerned if student attendance
were declining. Do these figures give evidence of a change in student attendance?

a) Write appropriate hypotheses.

b) Make a graph

c) Perform the test and find the p-value.

d) State your conclusion.

e) Do you think this difference is meaningful? Explain.




3. The Lending Club platform believes that it is loaning more money to people who rent their houses (as opposed to owning them) than they used to. They used to give out 38% of their loans to renters. Are they giving out more loans? 

https://www.openintro.org/data/index.php?data=loan50

a) Write appropriate hypotheses.

b) Make a graph

c) Perform the test and find the p-value.

d) State your conclusion.

e) Do you think this difference is meaningful? Explain.








